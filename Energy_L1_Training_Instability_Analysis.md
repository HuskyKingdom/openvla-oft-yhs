# Energy Lossä¸L1 Lossè”åˆè®­ç»ƒä¸ç¨³å®šæ€§åˆ†ææŠ¥å‘Š

## ğŸš¨ é—®é¢˜ç°è±¡æ€»ç»“

**è§‚å¯Ÿåˆ°çš„å¼‚å¸¸**ï¼š
- **è”åˆè®­ç»ƒ**: Energy Losså’ŒL1 LossåŒæ—¶è®­ç»ƒæ—¶å‡ºç°çªå˜å’Œä¸ç¨³å®š
- **å†»ç»“ä¸»å¹²**: å†»ç»“VLMä¸»å¹²æ—¶è®­ç»ƒç¨³å®š
- **ç†è®ºå›°æƒ‘**: è¡¨é¢ä¸Šä¸¤ä¸ªæŸå¤±çš„æ¢¯åº¦åº”è¯¥æ˜¯åˆ†ç¦»çš„

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### 1. Action Headçš„åŒé‡è§’è‰²é—®é¢˜ âš ï¸

**å…³é”®å‘ç°**: Action Headåœ¨è®­ç»ƒå¾ªç¯ä¸­æ‰®æ¼”äº†åŒé‡è§’è‰²ï¼

```python
# ç¬¬ä¸€ä¸ªè§’è‰²ï¼šç”Ÿæˆè´Ÿæ ·æœ¬ (488-502è¡Œ)
with torch.no_grad(): 
    action_head.eval()     
    for layer_idx in range(len(all_hiddents)):
        # ä½¿ç”¨action_headç”Ÿæˆlayer_actionsä½œä¸ºè´Ÿæ ·æœ¬
        current_actions = action_head.module.predict_action(hiddents_actions).detach()
        layer_actions.append(current_actions)
    action_head.train()

# ç¬¬äºŒä¸ªè§’è‰²ï¼šL1æŸå¤±è®¡ç®— (579-583è¡Œ)
if use_l1_regression:
    predicted_actions = action_head.module.predict_action(actions_hidden_states)
    loss = torch.nn.L1Loss()(ground_truth_actions, predicted_actions)
```

### 2. éšå«çš„è®­ç»ƒåŠ¨åŠ›å­¦è€¦åˆ ğŸ”„

**è€¦åˆè·¯å¾„**ï¼š
```
L1 Loss â†’ action_headå‚æ•°æ›´æ–° â†’ ä¸‹ä¸€batchçš„layer_actionså˜åŒ– â†’ energy lossè®¡ç®—å˜åŒ–
```

**å…·ä½“æœºåˆ¶**ï¼š
1. **å½“å‰batch**: L1 lossçš„backward()æ›´æ–°action_headå‚æ•°
2. **ä¼˜åŒ–å™¨æ­¥éª¤**: optimizer.step()åº”ç”¨æ›´æ–°
3. **ä¸‹ä¸€batch**: ç”¨æ›´æ–°åçš„action_headç”Ÿæˆæ–°çš„layer_actions
4. **Energyè®¡ç®—**: layer_actionsçš„å˜åŒ–å½±å“energy lossçš„è´Ÿæ ·æœ¬è´¨é‡
5. **åé¦ˆå¾ªç¯**: å½¢æˆéšæ€§çš„ç›¸äº’å½±å“

### 3. ä¼˜åŒ–å™¨ç«äº‰æ•ˆåº” âš¡

**åŒä¼˜åŒ–å™¨æœºåˆ¶**ï¼š
```python
optimizer = AdamW(trainable_params, lr=cfg.learning_rate)           # åŒ…å«action_head
energy_optimizer = AdamW(energy_trainable_params, lr=cfg.energy_learning_rate)  # ä»…energy_model
```

**å‚æ•°åˆ†å¸ƒ**ï¼š
- `trainable_params`: VLA + action_head + å…¶ä»–ç»„ä»¶
- `energy_trainable_params`: ä»…energy_modelå‚æ•°

**ç«äº‰é—®é¢˜**ï¼š
- Action Headå—åˆ°L1 lossé©±åŠ¨çš„æ›´æ–°
- Energy Modelè¯•å›¾é€‚åº”ä¸æ–­å˜åŒ–çš„è´Ÿæ ·æœ¬åˆ†å¸ƒ
- ä¸¤è€…æ›´æ–°é¢‘ç‡å’Œå¹…åº¦ä¸åŒï¼Œå¯èƒ½äº§ç”Ÿéœ‡è¡

### 4. ä¸ºä»€ä¹ˆå†»ç»“VLMä¸»å¹²æ—¶ç¨³å®šï¼Ÿ

**å†»ç»“æ•ˆæœåˆ†æ**ï¼š
```python
# å†»ç»“VLMä¸»å¹²æ—¶ï¼š
trainable_params â‰ˆ action_headå‚æ•°
```

**ç¨³å®šåŸå› **ï¼š
1. **å‚æ•°ç©ºé—´ç¼©å°**: å¯è®­ç»ƒå‚æ•°å¤§å¹…å‡å°‘ï¼Œäº¤äº’ç®€åŒ–
2. **æ›´æ–°ä¸€è‡´æ€§**: Action Headæˆä¸ºä¸»è¦ç„¦ç‚¹ï¼Œä¸¤ä¸ªlosséƒ½ä¾èµ–å®ƒ
3. **å‡å°‘ç«äº‰**: VLAä¸»å¹²ä¸å˜ï¼Œhidden statesæ›´ç¨³å®š
4. **ç®€åŒ–åŠ¨åŠ›å­¦**: ç³»ç»Ÿå¤æ‚åº¦å¤§å¹…é™ä½

## ğŸ› ï¸ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: æ¢¯åº¦éš”ç¦»ç­–ç•¥ â­â­â­â­â­

**æ ¸å¿ƒæ€æƒ³**: å®Œå…¨éš”ç¦»ä¸¤ä¸ªè®­ç»ƒè·¯å¾„

```python
def isolated_energy_training(vla, action_head, energy_model, batch, ...):
    """å®Œå…¨éš”ç¦»çš„energyè®­ç»ƒ"""
    
    # === ç¬¬ä¸€é˜¶æ®µï¼šL1 lossè®¡ç®—å’Œæ›´æ–° ===
    with torch.no_grad():
        # å†»ç»“energyç›¸å…³è®¡ç®—
        energy_model.eval()
    
    # æ­£å¸¸è®¡ç®—L1 loss
    output = vla(...)
    actions_hidden_states = extract_action_features(output)
    predicted_actions = action_head.module.predict_action(actions_hidden_states)
    l1_loss = torch.nn.L1Loss()(ground_truth_actions, predicted_actions)
    
    # L1åå‘ä¼ æ’­å’Œæ›´æ–°
    l1_loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    
    # === ç¬¬äºŒé˜¶æ®µï¼šEnergy lossè®¡ç®—å’Œæ›´æ–° ===
    with torch.no_grad():
        # é‡æ–°è®¡ç®—hidden statesï¼ˆä½¿ç”¨æ›´æ–°åçš„VLAï¼‰
        output_energy = vla(...)
        context_hidden_energy = output_energy.hidden_states[-1].detach()
        
        # ä½¿ç”¨æ›´æ–°åçš„action_headç”Ÿæˆlayer_actions
        action_head.eval()
        layer_actions = []
        for layer_idx in range(len(output_energy.hidden_states)):
            # ... ç”Ÿæˆlayer_actions ...
        action_head.train()
    
    # è®¡ç®—energy lossï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
    energy_model.train()
    energy_loss = compute_energy_loss(energy_model, context_hidden_energy, 
                                     ground_truth_actions, layer_actions)
    
    # Energyåå‘ä¼ æ’­å’Œæ›´æ–°
    energy_loss.backward()
    energy_optimizer.step()
    energy_optimizer.zero_grad()
```

### æ–¹æ¡ˆ2: å¼‚æ­¥è®­ç»ƒç­–ç•¥ â­â­â­â­

**æ ¸å¿ƒæ€æƒ³**: äº¤æ›¿è®­ç»ƒä¸¤ä¸ªç»„ä»¶

```python
def alternating_training_strategy(step, alternation_frequency=5):
    """äº¤æ›¿è®­ç»ƒç­–ç•¥"""
    
    if step % (alternation_frequency * 2) < alternation_frequency:
        # å‰Næ­¥ï¼šåªè®­ç»ƒVLA + Action Head
        train_mode = 'vla_only'
        energy_model.eval()
        for param in energy_model.parameters():
            param.requires_grad = False
            
    else:
        # åNæ­¥ï¼šåªè®­ç»ƒEnergy Model
        train_mode = 'energy_only'  
        vla.eval()
        action_head.eval()
        for param in vla.parameters():
            param.requires_grad = False
        for param in action_head.parameters():
            param.requires_grad = False
        
        energy_model.train()
        for param in energy_model.parameters():
            param.requires_grad = True
    
    return train_mode
```

### æ–¹æ¡ˆ3: ç¨³å®šåŒ–æŸå¤±æƒé‡ â­â­â­

**æ ¸å¿ƒæ€æƒ³**: åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡ï¼Œå‡å°‘ç›¸äº’å¹²æ‰°

```python
def adaptive_loss_weighting(step, l1_loss, energy_loss, loss_history):
    """è‡ªé€‚åº”æŸå¤±æƒé‡ï¼Œç»´æŒè®­ç»ƒç¨³å®šæ€§"""
    
    # è®¡ç®—æŸå¤±å˜åŒ–ç‡
    if len(loss_history['l1']) > 10:
        l1_variance = torch.var(torch.tensor(loss_history['l1'][-10:]))
        energy_variance = torch.var(torch.tensor(loss_history['energy'][-10:]))
        
        # å¦‚æœæŸä¸ªlossæ–¹å·®è¿‡å¤§ï¼Œé™ä½å…¶æƒé‡
        if l1_variance > 0.01:  # L1 lossä¸ç¨³å®š
            l1_weight = 0.5
            energy_weight = 1.0
        elif energy_variance > 0.1:  # Energy lossä¸ç¨³å®š
            l1_weight = 1.0
            energy_weight = 0.3
        else:
            l1_weight = 1.0
            energy_weight = 1.0
    else:
        l1_weight = 1.0
        energy_weight = 0.1  # æ—©æœŸä»¥L1ä¸ºä¸»
    
    return l1_weight, energy_weight
```

### æ–¹æ¡ˆ4: Layer Actionsç¼“å­˜ç­–ç•¥ â­â­â­â­

**æ ¸å¿ƒæ€æƒ³**: ç¼“å­˜layer_actionsï¼Œé¿å…å®æ—¶è®¡ç®—å¸¦æ¥çš„è€¦åˆ

```python
class LayerActionsCache:
    """Layer Actionsç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_size=1000, update_frequency=50):
        self.cache = {}
        self.cache_size = cache_size
        self.update_frequency = update_frequency
        self.last_update_step = 0
        
    def get_or_compute_layer_actions(self, batch_id, step, action_head, all_hiddens, num_patches, masks):
        """è·å–æˆ–è®¡ç®—layer actions"""
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¼“å­˜
        if step - self.last_update_step >= self.update_frequency:
            return self._compute_fresh_layer_actions(action_head, all_hiddens, num_patches, masks)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cache_key = self._generate_cache_key(batch_id)
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # ç¼“å­˜missï¼Œè®¡ç®—æ–°çš„
        layer_actions = self._compute_fresh_layer_actions(action_head, all_hiddens, num_patches, masks)
        
        # æ›´æ–°ç¼“å­˜
        if len(self.cache) >= self.cache_size:
            # åˆ é™¤æœ€è€çš„æ¡ç›®
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[cache_key] = layer_actions
        return layer_actions
```

### æ–¹æ¡ˆ5: è®¡ç®—å›¾å®Œå…¨åˆ†ç¦» â­â­â­â­â­

**æ ¸å¿ƒæ€æƒ³**: å½»åº•åˆ†ç¦»ä¸¤ä¸ªè®¡ç®—å›¾

```python
def completely_separated_training(vla, action_head, energy_model, batch, ...):
    """å®Œå…¨åˆ†ç¦»çš„è®­ç»ƒæµç¨‹"""
    
    # === Phase 1: VLA + Action Headè®­ç»ƒ ===
    # å®Œå…¨å†»ç»“energy model
    energy_model.eval()
    for param in energy_model.parameters():
        param.requires_grad = False
    
    # VLAå‰å‘ä¼ æ’­ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
    output_vla = vla(...)
    actions_hidden = extract_action_features(output_vla)
    predicted_actions = action_head(actions_hidden)
    l1_loss = torch.nn.L1Loss()(ground_truth_actions, predicted_actions)
    
    # L1åå‘ä¼ æ’­
    l1_loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    
    # === Phase 2: Energy Modelè®­ç»ƒ ===
    # å†»ç»“VLAå’ŒAction Head
    vla.eval()
    action_head.eval()
    for param in vla.parameters():
        param.requires_grad = False
    for param in action_head.parameters():
        param.requires_grad = False
    
    # é‡æ–°å‰å‘ä¼ æ’­ï¼ˆæ— æ¢¯åº¦ï¼‰
    with torch.no_grad():
        output_energy = vla(...)
        context_hidden = output_energy.hidden_states[-1]
        
        # ç”Ÿæˆç¨³å®šçš„layer_actions
        layer_actions = generate_layer_actions(action_head, output_energy.hidden_states)
    
    # æ¿€æ´»energy model
    energy_model.train()
    for param in energy_model.parameters():
        param.requires_grad = True
    
    # Energy lossè®¡ç®—å’Œåå‘ä¼ æ’­
    energy_loss = compute_energy_loss(energy_model, context_hidden, 
                                     ground_truth_actions, layer_actions)
    energy_loss.backward()
    energy_optimizer.step()
    energy_optimizer.zero_grad()
    
    # æ¢å¤æ‰€æœ‰æ¨¡å—ä¸ºè®­ç»ƒæ¨¡å¼
    vla.train()
    action_head.train()
    
    return l1_loss, energy_loss
```

## ğŸ“Š ä¸ºä»€ä¹ˆä¼šå‡ºç°çªå˜ï¼Ÿ

### æ•°å­¦åˆ†æï¼š

**ä¸ç¨³å®šçš„åé¦ˆå¾ªç¯**ï¼š
```
è®¾action_headå‚æ•°ä¸ºÎ¸ï¼ŒEnergy modelå‚æ•°ä¸ºÏ†

ç¬¬kæ­¥ï¼š
Î¸^(k+1) = Î¸^(k) - Î±â‚âˆ‡_Î¸ L1(Î¸^(k))
Ï†^(k+1) = Ï†^(k) - Î±â‚‚âˆ‡_Ï† Energy(Ï†^(k), layer_actions(Î¸^(k)))

é—®é¢˜ï¼šlayer_actionsä¾èµ–äºÎ¸ï¼Œä½†Î¸åœ¨åŒä¸€æ­¥è¢«L1 lossæ›´æ–°ï¼
```

**çªå˜è§¦å‘æ¡ä»¶**ï¼š
1. Action Headå‚æ•°çªç„¶å¤§å¹…æ›´æ–°ï¼ˆL1 loss spikeï¼‰
2. Layer Actionsåˆ†å¸ƒçªç„¶æ”¹å˜
3. Energy Modelé¢ä¸´å®Œå…¨ä¸åŒçš„è´Ÿæ ·æœ¬åˆ†å¸ƒ
4. Energy Lossæ¿€å¢ï¼Œåè¿‡æ¥å½±å“æ•´ä¸ªç³»ç»Ÿç¨³å®šæ€§

## ğŸ¯ æ¨èè§£å†³æ–¹æ¡ˆ

**ç«‹å³å®æ–½**: æ–¹æ¡ˆ5ï¼ˆè®¡ç®—å›¾å®Œå…¨åˆ†ç¦»ï¼‰
- **åŸå› **: å½»åº•æ¶ˆé™¤è€¦åˆï¼Œç¡®ä¿ç¨³å®šæ€§
- **å®ç°**: ä¸¤é˜¶æ®µè®­ç»ƒï¼Œæ¯ä¸ªé˜¶æ®µå®Œå…¨ç‹¬ç«‹
- **é£é™©**: æœ€ä½ï¼Œç†è®ºä¸Šä¿è¯ç¨³å®š

**å¤‡é€‰æ–¹æ¡ˆ**: æ–¹æ¡ˆ4ï¼ˆLayer Actionsç¼“å­˜ï¼‰
- **åŸå› **: å‡å°‘å®æ—¶è®¡ç®—çš„å˜åŒ–ï¼Œå¹³æ»‘è®­ç»ƒè¿‡ç¨‹
- **å®ç°**: ç¼“å­˜layer_actionsï¼Œé™ä½æ›´æ–°é¢‘ç‡
- **é£é™©**: ä¸­ç­‰ï¼Œéœ€è¦è°ƒæ•´ç¼“å­˜ç­–ç•¥

## ğŸ”§ å¿«é€Ÿä¿®å¤ä»£ç 

**ä¿®æ”¹æ‚¨çš„è®­ç»ƒå¾ªç¯ï¼ˆ1272-1274è¡Œï¼‰**ï¼š

```python
# åŸæ¥çš„ä»£ç ï¼š
# normalized_loss.backward()
# normalized_energy_loss.backward()

# ä¿®æ”¹ä¸ºåˆ†ç¦»å¼è®­ç»ƒï¼š
# Phase 1: VLAè®­ç»ƒ
energy_model.eval()
normalized_loss.backward()
optimizer.step()
optimizer.zero_grad()

# Phase 2: Energyè®­ç»ƒï¼ˆé‡æ–°è®¡ç®—ï¼Œç¡®ä¿æ— è€¦åˆï¼‰
with torch.no_grad():
    vla.eval()
    action_head.eval()
    # é‡æ–°è®¡ç®—energyç›¸å…³æ•°æ®
    _, _, fresh_energy_loss = run_forward_pass(
        vla=vla, energy_model=energy_model, batch=batch, ...
    )

energy_model.train()
vla.train()
action_head.train()

fresh_normalized_energy_loss = fresh_energy_loss / cfg.grad_accumulation_steps
fresh_normalized_energy_loss.backward()
energy_optimizer.step()
energy_optimizer.zero_grad()
```

è¿™ä¸ªä¿®æ”¹åº”è¯¥èƒ½ç«‹å³è§£å†³æ‚¨çœ‹åˆ°çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼

å…³é”®æ´å¯Ÿï¼š**çœ‹ä¼¼ç‹¬ç«‹çš„æŸå¤±å‡½æ•°ï¼Œå®é™…ä¸Šé€šè¿‡action_headçš„å‚æ•°æ›´æ–°å½¢æˆäº†éšæ€§è€¦åˆ**ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¾®å¦™ä½†é‡è¦çš„å‘ç°ï¼
